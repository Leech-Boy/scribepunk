---
layout: default
title: "AI Misinformation is Nothing to be Afraid of"
subtitle: "The Era of Trust"
categories: substack
---

<!--excerpt-start-->
<p>Firstly, I will not confess to writing a clickbait title, because I did not. What I have written is true, although it will require some explaining. The ability of AI to create extremely convincing misinformation has developed faster than society can adapt. An adaptation is necessary, however, I will argue that this adaptation is not one into an entirely new mode of living, rather it is a return to a more natural state.</p>
<!--excerpt-end-->
<p>The title of this essay “AI misinformation is nothing to be afraid of”, is my thesis and will be proven (hopefully) by the end. The subtitle, however, deserves special attention. I believe that we will enter a new era of trust, or else risk the collapse of our civilization. I do not mean we will enter a new era of trusting. We will enter an era in which information is believed on the basis of trust, rather than the form and content of the information itself.</p>
<p>The ability of generative AI to create misinformation in the form of photos, videos, or new stories may very well improve to the point that no human, organization, or program can distinguish fact from fiction without outside information. Once we reach this point, the only way you can trust something you see or read on the internet will be if it comes from a reputable source. This is what I mean by “The Era of Trust”. Trust will return to its place as the backbone of information exchange.</p>
<p>For most of my life, trust has not been necessary to exchange information. If a person presented a video of The President of the United States giving a speech, it went without saying, that the president did in fact give that speech. Whether the person who presented the video was a respected journalist or a crank, you could be sure that the video was genuine. Of course, I realize that creating fake videos has always been possible, however the work required to do so was great enough that there were far fewer such videos than there are now. And crucially, the number of experts who could identify such videos when they went viral was relatively high.</p>
<p>A video, or voice recording or image, for that matter could have been shared with key context left out. In this respect, it was still important to be aware of the trustworthiness of the source. But there was always a kernel of truth in the media presented. Even if the individual were the least trustworthy person alive, you had to reckon with the content of the media that they produced.</p>
<p>Historically speaking, this degree of trust that is owed to untrustworthy individuals or strangers is the anomaly, rather than the rule. Imagine what it must have been like in the time before information could be mechanically recorded and reproduced. There would be many newsworthy events for which nobody could produce irrefutable evidence of. When deciding whether a piece of news was true, your main tools were, “what are other people saying” and “has this source proven to be trustworthy”.</p>
<p>I believe that we are returning to this state. A state where it is often impossible to provide irrefutable evidence of any event. The difference is that instead of being hard to produce evidence, it is hard for the evidence to be irrefutable. Every piece of media will be suspect.</p>
<p>For years, photos, videos, and audio recordings have provided a kind of information that has bypassed the traditional channels of trust. The future of communication is not in waiting for Silicon Valley to produce a new piece of technology that will catch all information; it is to begin now, in building up the long abandoned machinery of trust and reputation.</p>
